####Deep Learning Course: Notes####

Data Analysis is a key aspect of ML workflow

Classifier --> box of rules
Learning Algo --> Procedure which:
  1. Creates the rules
  2. Finds Patterns(Eg:- If a fruit is heavier, it is more likely to be an apple)

COLLECT --> TRAIN CLASSIFIER --> MAKE PREDICTIONS
features for --> CLASSIFIER --> Prediction(LABEL)
a new entry

A good feature makes it easier to decide between two different things.

ANACONDA --> Environment for anything Data Science

JUPYTER Notebooks --> IDE for Python and many more.
  Ipython has many Jupyter notebooks to play with

PANDAS --> Python lib data [rows, columns, describe]
NUMPY --> Manipulate data, create data
  pd.DataFrame(np.random.randn(#rows, #cols))

SKLEARN --> An open source library to do things around ML, like:
  1. splitting test, train data
  2. Method fit() to create rules to train the classifier based on training data provided
  3. has classifier types(tree, KNN)
  4. Method to predict (.predict()) [FIT and PREDICT are objects of the classifier]
  5. Evaluate Model performance(.score())
  6.Find accuracy score (accuracy_score module)

  1. Helps in data set loading and manipulation
  2. Preprocessing pipelines and metrics
  3. Vast collection of ML algorithms, minimal code adjustments
  4. What difference models do + how various parameters for a given model perform
  5. train_test_split takes care of creating training & test data




